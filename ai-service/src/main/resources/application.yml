# Server Configuration
server:
  port: 8080

# Application Configuration
spring:
  application:
    name: ai-service
  
  # Ollama Configuration
  ai:
    ollama:
      base-url: http://localhost:11434
      temperature: 0.7
      init:
        pull-model-strategy: never
      chat:
        model: deepseek-r1:1.5b
      embedding:
        options:
          model: nomic-embed-text
      client:
        connection-timeout: 30000
        read-timeout: 30000
    model:
      embedding: ollama
    vectorstore:
      redis:
        initialize-schema: true
        index-name: bank_knowledge
        prefix: embedding
        dimensions: 768
        enabled: true
  
  # Redis Configuration
  data:
    redis:
      host: 192.168.162.40
      port: 6379
      password: cyj123456
      client-type: jedis
      database: 0

# Logging Configuration
logging:
  level:
    root: INFO
    org.springframework: DEBUG
    org.springframework.ai: TRACE
    org.springframework.data.redis: DEBUG
    org.springframework.boot.autoconfigure: DEBUG
    com.bank.aiservice: DEBUG
    org.springframework.context.annotation: TRACE
    org.springframework.beans.factory.support: DEBUG
    org.springframework.web.client: TRACE
    org.springframework.ai.ollama: TRACE

# CORS Configuration (Commented out)
# spring:
#   webflux:
#     cors:
#       allowed-origins: "*"
#       allowed-methods: GET,POST,PUT,DELETE,OPTIONS
#       allowed-headers: "*"
#       max-age: 3600 

debug: true 